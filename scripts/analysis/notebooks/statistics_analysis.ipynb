{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T14:09:33.718541Z",
     "start_time": "2025-04-15T14:09:26.827340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install --upgrade pip\n",
    "!{sys.executable} -m pip install ipywidgets\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ],
   "id": "e3a48471c896034d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: pip in c:\\users\\mikef\\anaconda3\\envs\\simgnn\\lib\\site-packages (25.0.1)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\mikef\\anaconda3\\envs\\simgnn\\lib\\site-packages (8.1.5)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\mikef\\anaconda3\\envs\\simgnn\\lib\\site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\mikef\\anaconda3\\envs\\simgnn\\lib\\site-packages (from ipywidgets) (8.18.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\mikef\\anaconda3\\envs\\simgnn\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in c:\\users\\mikef\\anaconda3\\envs\\simgnn\\lib\\site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in c:\\users\\mikef\\anaconda3\\envs\\simgnn\\lib\\site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: decorator in c:\\users\\mikef\\anaconda3\\envs\\simgnn\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\mikef\\anaconda3\\envs\\simgnn\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\mikef\\anaconda3\\envs\\simgnn\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\mikef\\anaconda3\\envs\\simgnn\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\mikef\\anaconda3\\envs\\simgnn\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\mikef\\anaconda3\\envs\\simgnn\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\mikef\\anaconda3\\envs\\simgnn\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (4.12.2)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\mikef\\anaconda3\\envs\\simgnn\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (1.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\mikef\\anaconda3\\envs\\simgnn\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\mikef\\anaconda3\\envs\\simgnn\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\mikef\\anaconda3\\envs\\simgnn\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\mikef\\anaconda3\\envs\\simgnn\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\mikef\\anaconda3\\envs\\simgnn\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\mikef\\anaconda3\\envs\\simgnn\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.3)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T14:09:33.749799Z",
     "start_time": "2025-04-15T14:09:33.718541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_approx_results(file_path, fill_n_density=None):\n",
    "    df = pd.read_excel(file_path)\n",
    "    df.dropna(how='all', inplace=True)\n",
    "\n",
    "    # Convert graph IDs to string to ensure consistent dtype\n",
    "    df['graph_id_1'] = df['graph_id_1'].astype(str)\n",
    "    df['graph_id_2'] = df['graph_id_2'].astype(str)\n",
    "\n",
    "    numeric_cols = [\n",
    "        'ged', 'accuracy', 'absolute_error', 'squared_error',\n",
    "        'runtime', 'memory_usage_mb',\n",
    "        'graph1_n', 'graph1_density', 'graph2_n', 'graph2_density'\n",
    "    ]\n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "    if fill_n_density is not None:\n",
    "        # Ensure fill DataFrame also has string-based IDs\n",
    "        fill_n_density['graph_id_1'] = fill_n_density['graph_id_1'].astype(str)\n",
    "        fill_n_density['graph_id_2'] = fill_n_density['graph_id_2'].astype(str)\n",
    "\n",
    "        needed_cols = ['graph1_n', 'graph2_n', 'graph1_density', 'graph2_density']\n",
    "        ref_cols = ['graph_id_1', 'graph_id_2'] + needed_cols\n",
    "        ref = fill_n_density[ref_cols].drop_duplicates()\n",
    "\n",
    "        merged = pd.merge(\n",
    "            df, ref,\n",
    "            how='left',\n",
    "            on=['graph_id_1','graph_id_2'],\n",
    "            suffixes=('', '_ref')\n",
    "        )\n",
    "        for c in needed_cols:\n",
    "            merged[c] = np.where(\n",
    "                merged[c].isna(),\n",
    "                merged[f\"{c}_ref\"],\n",
    "                merged[c]\n",
    "            )\n",
    "        drop_cols = [f\"{c}_ref\" for c in needed_cols if f\"{c}_ref\" in merged.columns]\n",
    "        merged.drop(columns=drop_cols, inplace=True)\n",
    "        df = merged\n",
    "\n",
    "    df.dropna(subset=['graph_id_1','graph_id_2'], inplace=True)\n",
    "    return df\n",
    "\n",
    "def load_exact_results(file_path):\n",
    "    \"\"\"\n",
    "    Load exact GED results from an XLSX file.\n",
    "    Compute 'ged_exact' as the median of (min_ged, max_ged) if they differ,\n",
    "    else min_ged (or max_ged).\n",
    "    \"\"\"\n",
    "    df = pd.read_excel(file_path)\n",
    "    df.dropna(how='all', inplace=True)\n",
    "\n",
    "    # Convert graph IDs to string\n",
    "    df['graph_id_1'] = df['graph_id_1'].astype(str)\n",
    "    df['graph_id_2'] = df['graph_id_2'].astype(str)\n",
    "\n",
    "    for col in ['min_ged', 'max_ged']:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "    def compute_ged_exact(row):\n",
    "        if pd.notnull(row['min_ged']) and pd.notnull(row['max_ged']) and row['min_ged'] != row['max_ged']:\n",
    "            return (row['min_ged'] + row['max_ged']) / 2.0\n",
    "        else:\n",
    "            return row['min_ged']  # or row['max_ged']\n",
    "\n",
    "    df['ged_exact'] = df.apply(compute_ged_exact, axis=1)\n",
    "    df.dropna(subset=['graph_id_1','graph_id_2','ged_exact'], inplace=True)\n",
    "    return df\n",
    "\n",
    "def compute_relative_accuracy(ged_approx, ged_exact):\n",
    "    if ged_exact == 0 or ged_approx is None or ged_exact is None:\n",
    "        return np.nan\n",
    "    elif ged_approx >= (ged_exact * 2):\n",
    "        return 0\n",
    "    return 1 - abs(ged_approx - ged_exact)/ged_exact"
   ],
   "id": "16bd4b45a44a0bbe",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T14:09:33.763388Z",
     "start_time": "2025-04-15T14:09:33.750519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "datasets = {\n",
    "    \"AIDS\": {\n",
    "        \"HED\":      r\"C:\\project_data\\results\\gedlib\\AIDS\\AIDS_HED_results.xlsx\",\n",
    "        \"IPFP\":     r\"C:\\project_data\\results\\gedlib\\AIDS\\AIDS_IPFP_results.xlsx\",\n",
    "        \"SimGNN\":    r\"C:\\project_data\\results\\neural\\AIDS\\performance.xlsx\",\n",
    "        \"Exact\":    r\"C:\\project_data\\results\\exact_ged\\AIDS\\merged\\results.xlsx\"\n",
    "    },\n",
    "    \"IMDB-BINARY\": {\n",
    "        \"HED\":      r\"C:\\project_data\\results\\gedlib\\IMDB-BINARY\\IMDB-BINARY_HED_results.xlsx\",\n",
    "        \"IPFP\":     r\"C:\\project_data\\results\\gedlib\\IMDB-BINARY\\IMDB-BINARY_IPFP_results.xlsx\",\n",
    "        \"SimGNN\":   r\"C:\\project_data\\results\\neural\\IMDB-BINARY\\performance.xlsx\",\n",
    "        \"Exact\":    r\"C:\\project_data\\results\\exact_ged\\IMDB-BINARY\\merged\\results.xlsx\"\n",
    "    },\n",
    "    \"PROTEINS\": {\n",
    "        \"HED\":      r\"C:\\project_data\\results\\gedlib\\PROTEINS\\PROTEINS_HED_results.xlsx\",\n",
    "        \"IPFP\":     r\"C:\\project_data\\results\\gedlib\\PROTEINS\\PROTEINS_IPFP_results.xlsx\",\n",
    "        \"SimGNN\":   r\"C:\\project_data\\results\\neural\\PROTEINS\\performance.xlsx\",\n",
    "        \"Exact\":    r\"C:\\project_data\\results\\exact_ged\\PROTEINS\\merged\\results.xlsx\"\n",
    "    }\n",
    "}"
   ],
   "id": "6ba62d05a340b433",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T14:29:49.511815Z",
     "start_time": "2025-04-15T14:09:33.972130Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def adjust_ids(df):\n",
    "    # Convert id columns to integer, add one, then back to string\n",
    "    for col in ['graph_id_1', 'graph_id_2']:\n",
    "        df[col] = df[col].astype(int) - 1\n",
    "        df[col] = df[col].astype(str)\n",
    "    return df\n",
    "\n",
    "data = {}\n",
    "\n",
    "for dset, paths in datasets.items():\n",
    "    df_simgnn = load_approx_results(paths[\"SimGNN\"])\n",
    "    df_exact  = load_exact_results(paths[\"Exact\"])\n",
    "\n",
    "    df_hed  = load_approx_results(paths[\"HED\"], fill_n_density=df_simgnn)\n",
    "    df_ipfp = load_approx_results(paths[\"IPFP\"], fill_n_density=df_simgnn)\n",
    "\n",
    "    # Adjust ids for HED and IPFP so that they start from 1.\n",
    "    df_exact_copy = df_exact.copy()\n",
    "    df_exact = adjust_ids(df_exact)\n",
    "\n",
    "    # For consistency, fill SimGNN from itself:\n",
    "    df_simgnn_filled = load_approx_results(paths[\"SimGNN\"], fill_n_density=df_simgnn)\n",
    "\n",
    "    # Merge approximate with exact (intersection in memory)\n",
    "    df_hed  = pd.merge(df_hed,  df_exact, on=['graph_id_1','graph_id_2'], how='inner', suffixes=('', '_exact'))\n",
    "    df_ipfp = pd.merge(df_ipfp, df_exact, on=['graph_id_1','graph_id_2'], how='inner', suffixes=('', '_exact'))\n",
    "    df_simgnn_filled = pd.merge(df_simgnn_filled, df_exact_copy, on=['graph_id_1','graph_id_2'], how='inner', suffixes=('', '_exact'))\n",
    "\n",
    "    # Compute metrics\n",
    "    for df_approx in [df_hed, df_ipfp, df_simgnn_filled]:\n",
    "        if 'ged_exact' in df_approx.columns and 'ged' in df_approx.columns:\n",
    "            df_approx['absolute_error'] = abs(df_approx['ged'] - df_approx['ged_exact'])\n",
    "            df_approx['squared_error']  = (df_approx['ged'] - df_approx['ged_exact'])**2\n",
    "            df_approx['accuracy'] = df_approx.apply(\n",
    "                lambda row: compute_relative_accuracy(row['ged'], row['ged_exact'])\n",
    "                            if pd.notnull(row['ged_exact']) else np.nan,\n",
    "                axis=1\n",
    "            )\n",
    "            df_approx['graph_size'] = (df_approx['graph1_n'] + df_approx['graph2_n']) / 2.0\n",
    "            df_approx['graph_density'] = (df_approx['graph1_density'] + df_approx['graph2_density']) / 2.0\n",
    "\n",
    "    data[dset] = {\n",
    "        \"HED\":    df_hed,\n",
    "        \"IPFP\":   df_ipfp,\n",
    "        \"SimGNN\": df_simgnn_filled\n",
    "    }"
   ],
   "id": "19b73b15ee356d5",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T14:44:34.770246Z",
     "start_time": "2025-04-15T14:44:34.691601Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Code Block 1: Descriptive Statistics Functions\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "def compute_mae(df, pred_col='ged', true_col='ged_exact'):\n",
    "    \"\"\"\n",
    "    Compute Mean Absolute Error (MAE) for GED.\n",
    "    \"\"\"\n",
    "    if pred_col in df.columns and true_col in df.columns:\n",
    "        errors = abs(df[pred_col] - df[true_col])\n",
    "        return errors.mean()\n",
    "    return np.nan\n",
    "\n",
    "def compute_mse(df, pred_col='ged', true_col='ged_exact'):\n",
    "    \"\"\"\n",
    "    Compute Mean Squared Error (MSE) for GED.\n",
    "    \"\"\"\n",
    "    if pred_col in df.columns and true_col in df.columns:\n",
    "        errors = (df[pred_col] - df[true_col]) ** 2\n",
    "        return errors.mean()\n",
    "    return np.nan\n",
    "\n",
    "def compute_mre(df, pred_col='ged', true_col='ged_exact'):\n",
    "    \"\"\"\n",
    "    Compute Mean Relative Error (MRE) for GED.\n",
    "    \"\"\"\n",
    "    if pred_col in df.columns and true_col in df.columns:\n",
    "        # Filter out rows where true_col is zero to avoid division by zero\n",
    "        valid_df = df[df[true_col] > 0]\n",
    "        if len(valid_df) == 0:\n",
    "            return np.nan\n",
    "        relative_errors = abs(valid_df[pred_col] - valid_df[true_col]) / valid_df[true_col]\n",
    "        return relative_errors.mean()\n",
    "    return np.nan\n",
    "\n",
    "def compute_median_metrics(df):\n",
    "    \"\"\"\n",
    "    Compute medians for MRE, runtime, MAE, and MSE.\n",
    "    Returns a dictionary with these median values.\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    if 'runtime' in df.columns:\n",
    "        metrics['median_runtime'] = df['runtime'].median()\n",
    "    if 'absolute_error' in df.columns:\n",
    "        metrics['median_MAE'] = df['absolute_error'].median()\n",
    "    elif 'ged' in df.columns and 'ged_exact' in df.columns:\n",
    "        metrics['median_MAE'] = abs(df['ged'] - df['ged_exact']).median()\n",
    "    if 'squared_error' in df.columns:\n",
    "        metrics['median_MSE'] = df['squared_error'].median()\n",
    "    elif 'ged' in df.columns and 'ged_exact' in df.columns:\n",
    "        metrics['median_MSE'] = ((df['ged'] - df['ged_exact'])**2).median()\n",
    "    if 'ged' in df.columns and 'ged_exact' in df.columns:\n",
    "        valid_df = df[df['ged_exact'] > 0]\n",
    "        if len(valid_df) > 0:\n",
    "            rel_errors = abs(valid_df['ged'] - valid_df['ged_exact']) / valid_df['ged_exact']\n",
    "            metrics['median_MRE'] = rel_errors.median()\n",
    "    return metrics\n",
    "\n",
    "def runtime_frequency(df, bins=10):\n",
    "    \"\"\"\n",
    "    Compute the frequency distribution of runtime.\n",
    "    Returns a tuple: (bin_edges, frequency_counts).\n",
    "    \"\"\"\n",
    "    if 'runtime' in df.columns:\n",
    "        counts, bin_edges = np.histogram(df['runtime'].dropna(), bins=bins)\n",
    "        return bin_edges, counts\n",
    "    return None, None\n",
    "\n",
    "def descriptive_stats(df):\n",
    "    \"\"\"\n",
    "    Compute a set of descriptive statistics for key metrics.\n",
    "    Returns a dictionary with the following:\n",
    "      - MAE and MSE (mean, median, standard deviation)\n",
    "      - MRE (mean, median, std)\n",
    "      - Runtime (mean, median, std)\n",
    "      - Graph size (mean, median, std) if available.\n",
    "    \"\"\"\n",
    "    stats_dict = {}\n",
    "\n",
    "    # Mean Relative Error (MRE) statistics\n",
    "    if 'ged' in df.columns and 'ged_exact' in df.columns:\n",
    "        valid_df = df[\n",
    "            (df['ged'].notna()) &\n",
    "            (df['ged_exact'].notna()) &\n",
    "            (df['ged_exact'] > 0)\n",
    "        ]\n",
    "\n",
    "        if len(valid_df) > 0:\n",
    "            rel_errors = abs(valid_df['ged'] - valid_df['ged_exact']) / abs(valid_df['ged_exact'])\n",
    "            stats_dict['MRE_mean'] = rel_errors.mean()\n",
    "            stats_dict['MRE_median'] = rel_errors.median()\n",
    "            stats_dict['MRE_std'] = rel_errors.std()\n",
    "\n",
    "    # MAE and MSE metrics\n",
    "    if 'ged' in df.columns and 'ged_exact' in df.columns:\n",
    "        valid_df = df[\n",
    "            (df['ged'].notna()) &\n",
    "            (df['ged_exact'].notna()) &\n",
    "            (df['ged'] < (df['ged_exact'] * 2))\n",
    "        ]\n",
    "\n",
    "        abs_err = abs(valid_df['ged'] - valid_df['ged_exact'])\n",
    "        sq_err  = (valid_df['ged'] - valid_df['ged_exact']) ** 2\n",
    "\n",
    "        stats_dict['MAE_mean'] = abs_err.mean()\n",
    "        stats_dict['MAE_median'] = abs_err.median()\n",
    "        stats_dict['MSE_mean'] = sq_err.mean()\n",
    "        stats_dict['MSE_median'] = sq_err.median()\n",
    "\n",
    "    # Runtime statistics.\n",
    "    if 'runtime' in df.columns:\n",
    "        stats_dict['runtime_mean'] = df['runtime'].mean()\n",
    "        stats_dict['runtime_median'] = df['runtime'].median()\n",
    "        stats_dict['runtime_std'] = df['runtime'].std()\n",
    "\n",
    "    # Graph size statistics.\n",
    "    if 'graph_size' in df.columns:\n",
    "        stats_dict['graph_size_mean'] = df['graph_size'].mean()\n",
    "        stats_dict['graph_size_median'] = df['graph_size'].median()\n",
    "        stats_dict['graph_size_std'] = df['graph_size'].std()\n",
    "\n",
    "    return stats_dict"
   ],
   "id": "1139e581a91a7c8e",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T14:44:39.271027Z",
     "start_time": "2025-04-15T14:44:38.797437Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Code Block 2: Aggregating Statistics, Printing the Results, and Saving to Excel\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create a list to accumulate results for each dataset and algorithm.\n",
    "results_list = []\n",
    "\n",
    "# Assume 'data' is the dictionary defined earlier that maps dataset names to a dict\n",
    "# of DataFrames for \"HED\", \"IPFP\", and \"SimGNN\".\n",
    "for dset, algos in data.items():\n",
    "    for algo, df in algos.items():\n",
    "        # Use the functions from Code Block 1 to compute descriptive statistics.\n",
    "        stats_dict = descriptive_stats(df)\n",
    "        median_metrics = compute_median_metrics(df)\n",
    "        # Merge the computed statistics.\n",
    "        combined_stats = {**stats_dict, **median_metrics}\n",
    "        combined_stats['Dataset'] = dset\n",
    "        combined_stats['Algorithm'] = algo\n",
    "        results_list.append(combined_stats)\n",
    "\n",
    "# Create a DataFrame to display the results.\n",
    "results_df = pd.DataFrame(results_list)\n",
    "\n",
    "# Optional: Reorder the columns to show 'Dataset' and 'Algorithm' first.\n",
    "cols_order = ['Dataset', 'Algorithm'] + [col for col in results_df.columns if col not in ['Dataset', 'Algorithm']]\n",
    "results_df = results_df[cols_order]\n",
    "\n",
    "# Print the results table.\n",
    "print(\"Descriptive Statistics Table:\")\n",
    "print(results_df)\n",
    "\n",
    "# Save the results table to an Excel file.\n",
    "output_file = r\"C:\\project_data\\results\\analysis\\statistics_analysis_results.xlsx\"\n",
    "results_df.to_excel(output_file, index=False)\n",
    "print(f\"\\nResults saved to {output_file}\")\n",
    "\n",
    "# Now, compute and print runtime frequency and regression analysis results.\n",
    "print(\"\\nAdditional Analyses (Runtime Frequency and Regression Analysis):\")\n",
    "for dset, algos in data.items():\n",
    "    for algo, df in algos.items():\n",
    "        print(f\"\\n--- {dset} - {algo} ---\")\n",
    "\n",
    "        # Compute and print runtime frequency distribution.\n",
    "        bin_edges, counts = runtime_frequency(df)\n",
    "        if bin_edges is not None:\n",
    "            print(\"Runtime Frequency Distribution:\")\n",
    "            print(\"Bin Edges:\", bin_edges)\n",
    "            print(\"Counts:\", counts)\n",
    "        else:\n",
    "            print(\"Runtime frequency distribution: Data not available.\")\n"
   ],
   "id": "5ba1b5f21c5a24c7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive Statistics Table:\n",
      "       Dataset Algorithm  MRE_mean  MRE_median   MRE_std   MAE_mean  \\\n",
      "0         AIDS       HED  1.149731    0.833333  1.137125   7.251887   \n",
      "1         AIDS      IPFP  2.618761    2.166667  2.111480  12.812565   \n",
      "2         AIDS    SimGNN  0.698819    0.544637  0.774850  10.099670   \n",
      "3  IMDB-BINARY       HED  1.000000    1.000000  0.000000  53.922779   \n",
      "4  IMDB-BINARY      IPFP  0.000226    0.000000  0.005786   0.005361   \n",
      "5  IMDB-BINARY    SimGNN  0.735452    0.784702  0.408576  43.960600   \n",
      "6     PROTEINS       HED  0.741790    0.776923  0.128479  47.319380   \n",
      "7     PROTEINS      IPFP  0.114160    0.081967  0.120760   4.837084   \n",
      "8     PROTEINS    SimGNN  0.744223    0.783402  0.120351  47.749011   \n",
      "\n",
      "   MAE_median     MSE_mean   MSE_median  runtime_mean  runtime_median  \\\n",
      "0    4.125000   162.265039    17.015625      2.732141        2.397600   \n",
      "1   12.000000   232.216361   144.000000      0.013975        0.005370   \n",
      "2    2.641075   522.250851     6.975278      0.004570        0.004316   \n",
      "3   47.000000  4059.400631  2209.000000      0.164851        0.000245   \n",
      "4    0.000000     0.016569     0.000000      0.287478        0.177514   \n",
      "5   36.983870  2991.955262  1367.806628      0.004570        0.004004   \n",
      "6   39.000000  3443.382076  1521.000000      3.981228        4.023700   \n",
      "7    4.000000    33.719852    16.000000      0.007812        0.002687   \n",
      "8   39.115412  3536.471128  1530.015466      0.002087        0.001993   \n",
      "\n",
      "   runtime_std  graph_size_mean  graph_size_median  graph_size_std  \\\n",
      "0     1.378005        29.000000               29.0        0.000000   \n",
      "1     0.019243        29.000000               29.0        0.000000   \n",
      "2     0.002528        12.537697               10.5        6.580455   \n",
      "3     1.218647        26.000000               26.0        0.000000   \n",
      "4     0.309778        26.000000               26.0        0.000000   \n",
      "5     0.003836        16.486050               15.5        3.758209   \n",
      "6     3.316796        34.500000               34.5        0.000000   \n",
      "7     0.050911        32.754363               27.0       20.221666   \n",
      "8     0.003044        17.359337               16.5        6.830167   \n",
      "\n",
      "   median_runtime  median_MAE   median_MSE  median_MRE  \n",
      "0        2.397600    5.500000    30.250000    0.833333  \n",
      "1        0.005370   12.000000   144.000000    2.166667  \n",
      "2        0.004316    3.249331    10.558154    0.544637  \n",
      "3        0.000245   46.000000  2116.000000    1.000000  \n",
      "4        0.177514    0.000000     0.000000    0.000000  \n",
      "5        0.004004   35.117490  1233.238127    0.784702  \n",
      "6        4.023700   39.000000  1521.000000    0.776923  \n",
      "7        0.002687    4.000000    16.000000    0.081967  \n",
      "8        0.001993   39.111853  1529.737072    0.783402  \n",
      "\n",
      "Results saved to C:\\project_data\\results\\analysis\\statistics_analysis_results.xlsx\n",
      "\n",
      "Additional Analyses (Runtime Frequency and Regression Analysis):\n",
      "\n",
      "--- AIDS - HED ---\n",
      "Runtime Frequency Distribution:\n",
      "Bin Edges: [1.00783000e-04 9.99380705e-01 1.99866063e+00 2.99794055e+00\n",
      " 3.99722047e+00 4.99650039e+00 5.99578031e+00 6.99506023e+00\n",
      " 7.99434016e+00 8.99362008e+00 9.99290000e+00]\n",
      "Counts: [  69 1215 4261  192  312  194  122   84   49   53]\n",
      "\n",
      "--- AIDS - IPFP ---\n",
      "Runtime Frequency Distribution:\n",
      "Bin Edges: [6.73950000e-05 2.64474555e-02 5.28275160e-02 7.92075765e-02\n",
      " 1.05587637e-01 1.31967697e-01 1.58347758e-01 1.84727818e-01\n",
      " 2.11107879e-01 2.37487939e-01 2.63868000e-01]\n",
      "Counts: [7644  998  260   69   34    9    6    1    1    2]\n",
      "\n",
      "--- AIDS - SimGNN ---\n",
      "Runtime Frequency Distribution:\n",
      "Bin Edges: [0.00099969 0.01685879 0.0327179  0.048577   0.0644361  0.08029521\n",
      " 0.09615431 0.11201341 0.12787251 0.14373162 0.15959072]\n",
      "Counts: [20327    70     9     5     0     1     0     0     0     1]\n",
      "\n",
      "--- IMDB-BINARY - HED ---\n",
      "Runtime Frequency Distribution:\n",
      "Bin Edges: [1.00076000e-04 9.99950068e-01 1.99980006e+00 2.99965005e+00\n",
      " 3.99950005e+00 4.99935004e+00 5.99920003e+00 6.99905002e+00\n",
      " 7.99890002e+00 8.99875001e+00 9.99860000e+00]\n",
      "Counts: [33473     0     0     0     0     0     0     7   232   374]\n",
      "\n",
      "--- IMDB-BINARY - IPFP ---\n",
      "Runtime Frequency Distribution:\n",
      "Bin Edges: [3.89712000e-04 2.25079741e-01 4.49769770e-01 6.74459798e-01\n",
      " 8.99149827e-01 1.12383986e+00 1.34852988e+00 1.57321991e+00\n",
      " 1.79790994e+00 2.02259997e+00 2.24729000e+00]\n",
      "Counts: [2444  882  486  146  102   59   41   15   12    5]\n",
      "\n",
      "--- IMDB-BINARY - SimGNN ---\n",
      "Runtime Frequency Distribution:\n",
      "Bin Edges: [0.         0.01795084 0.03590169 0.05385253 0.07180338 0.08975422\n",
      " 0.10770507 0.12565591 0.14360676 0.1615576  0.17950845]\n",
      "Counts: [34063     0     0     0     0     1     6     1    14     1]\n",
      "\n",
      "--- PROTEINS - HED ---\n",
      "Runtime Frequency Distribution:\n",
      "Bin Edges: [1.00007000e-04 1.00007001e+00 2.00004001e+00 3.00001000e+00\n",
      " 3.99998000e+00 4.99995000e+00 5.99992000e+00 6.99989000e+00\n",
      " 7.99986000e+00 8.99983000e+00 9.99980000e+00]\n",
      "Counts: [6278  867 1385 1605 1775 1729 1848 1861 1626 1408]\n",
      "\n",
      "--- PROTEINS - IPFP ---\n",
      "Runtime Frequency Distribution:\n",
      "Bin Edges: [1.09191000e-04 2.10882272e-01 4.21655353e-01 6.32428434e-01\n",
      " 8.43201515e-01 1.05397460e+00 1.26474768e+00 1.47552076e+00\n",
      " 1.68629384e+00 1.89706692e+00 2.10784000e+00]\n",
      "Counts: [2978    4    0    0    1    0    1    0    0    1]\n",
      "\n",
      "--- PROTEINS - SimGNN ---\n",
      "Runtime Frequency Distribution:\n",
      "Bin Edges: [0.00177741 0.0413934  0.08100939 0.12062538 0.16024137 0.19985735\n",
      " 0.23947334 0.27908933 0.31870532 0.35832131 0.3979373 ]\n",
      "Counts: [20377     2     2     0     0     0     0     0     0     1]\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T14:29:50.491975Z",
     "start_time": "2025-04-15T14:29:50.309446Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# For each algorithm, count pearson and spearman correlations on each dataset and overall on 3 datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# List to accumulate dataset-level correlation results.\n",
    "correlation_results = []\n",
    "\n",
    "# Compute per-dataset correlations.\n",
    "for dset, algos in data.items():\n",
    "    for algo, df in algos.items():\n",
    "        # Filter valid rows.\n",
    "        valid_df = df[(df['ged'].notna()) & (df['ged_exact'].notna())]\n",
    "        if len(valid_df) > 1:\n",
    "            pearson_corr, _ = stats.pearsonr(valid_df['ged'], valid_df['ged_exact'])\n",
    "            spearman_corr, _ = stats.spearmanr(valid_df['ged'], valid_df['ged_exact'])\n",
    "        else:\n",
    "            pearson_corr = np.nan\n",
    "            spearman_corr = np.nan\n",
    "        correlation_results.append({\n",
    "            'Dataset': dset,\n",
    "            'Algorithm': algo,\n",
    "            'Pearson': pearson_corr,\n",
    "            'Spearman': spearman_corr\n",
    "        })\n",
    "\n",
    "# Create a DataFrame from the dataset-level results.\n",
    "dataset_corr_df = pd.DataFrame(correlation_results)\n",
    "print(\"Dataset-Level Correlations:\")\n",
    "print(dataset_corr_df)\n",
    "\n",
    "# Now compute overall correlations per algorithm across all datasets.\n",
    "overall_results = []\n",
    "# Aggregate data per algorithm.\n",
    "method_data = {}\n",
    "for dset, algos in data.items():\n",
    "    for algo, df in algos.items():\n",
    "        if algo not in method_data:\n",
    "            method_data[algo] = []\n",
    "        method_data[algo].append(df)\n",
    "\n",
    "print(\"\\nOverall Correlations per Algorithm:\")\n",
    "for algo, dfs in method_data.items():\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "    valid_df = combined_df[(combined_df['ged'].notna()) & (combined_df['ged_exact'].notna())]\n",
    "    if len(valid_df) > 1:\n",
    "        pearson_corr, _ = stats.pearsonr(valid_df['ged'], valid_df['ged_exact'])\n",
    "        spearman_corr, _ = stats.spearmanr(valid_df['ged'], valid_df['ged_exact'])\n",
    "    else:\n",
    "        pearson_corr = np.nan\n",
    "        spearman_corr = np.nan\n",
    "    overall_results.append({\n",
    "        'Algorithm': algo,\n",
    "        'Pearson': pearson_corr,\n",
    "        'Spearman': spearman_corr\n",
    "    })\n",
    "\n",
    "overall_corr_df = pd.DataFrame(overall_results)\n",
    "print(overall_corr_df)"
   ],
   "id": "3d24420b227b632e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset-Level Correlations:\n",
      "       Dataset Algorithm   Pearson  Spearman\n",
      "0         AIDS       HED  0.944368  0.343902\n",
      "1         AIDS      IPFP  0.979375  0.571994\n",
      "2         AIDS    SimGNN  0.981745  0.389424\n",
      "3  IMDB-BINARY       HED       NaN       NaN\n",
      "4  IMDB-BINARY      IPFP  0.999995  0.999994\n",
      "5  IMDB-BINARY    SimGNN  0.621308  0.627997\n",
      "6     PROTEINS       HED  0.835628  0.802561\n",
      "7     PROTEINS      IPFP  0.998009  0.994016\n",
      "8     PROTEINS    SimGNN  0.906692  0.879707\n",
      "\n",
      "Overall Correlations per Algorithm:\n",
      "  Algorithm   Pearson  Spearman\n",
      "0       HED  0.222073  0.035582\n",
      "1      IPFP  0.985443  0.880676\n",
      "2    SimGNN  0.691586  0.781774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikef\\AppData\\Local\\Temp\\ipykernel_10500\\1142606708.py:15: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  pearson_corr, _ = stats.pearsonr(valid_df['ged'], valid_df['ged_exact'])\n",
      "C:\\Users\\mikef\\AppData\\Local\\Temp\\ipykernel_10500\\1142606708.py:16: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  spearman_corr, _ = stats.spearmanr(valid_df['ged'], valid_df['ged_exact'])\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T14:29:50.679338Z",
     "start_time": "2025-04-15T14:29:50.573133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def compute_fraction_within_margin(df, margin=0.1):\n",
    "    \"\"\"\n",
    "    Compute the fraction of GED predictions within a relative margin of the true GED.\n",
    "    A prediction is considered within margin if:\n",
    "      |ged - ged_exact| / ged_exact <= margin\n",
    "    \"\"\"\n",
    "    valid_df = df[(df['ged'].notna()) & (df['ged_exact'].notna())]\n",
    "    if len(valid_df) == 0:\n",
    "        return np.nan\n",
    "    relative_error = abs(valid_df['ged'] - valid_df['ged_exact']) / valid_df['ged_exact']\n",
    "    return (relative_error <= margin).sum() / len(valid_df)\n",
    "\n",
    "# Define the margins: 5%, 10% and 20%\n",
    "margins = [0.05, 0.10, 0.20]\n",
    "\n",
    "# Compute fraction for each dataset and algorithm separately\n",
    "print(\"Fraction of predictions within margin for each dataset and algorithm:\")\n",
    "for dset, algos in data.items():\n",
    "    print(f\"\\nDataset: {dset}\")\n",
    "    for algo, df in algos.items():\n",
    "        print(f\"  Algorithm: {algo}\")\n",
    "        for margin in margins:\n",
    "            fraction = compute_fraction_within_margin(df, margin=margin)\n",
    "            print(f\"    Fraction within {int(margin*100)}% margin: {fraction:.2%}\")"
   ],
   "id": "7755a4479c9e34ac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of predictions within margin for each dataset and algorithm:\n",
      "\n",
      "Dataset: AIDS\n",
      "  Algorithm: HED\n",
      "    Fraction within 5% margin: 0.99%\n",
      "    Fraction within 10% margin: 2.93%\n",
      "    Fraction within 20% margin: 7.36%\n",
      "  Algorithm: IPFP\n",
      "    Fraction within 5% margin: 0.06%\n",
      "    Fraction within 10% margin: 1.75%\n",
      "    Fraction within 20% margin: 5.49%\n",
      "  Algorithm: SimGNN\n",
      "    Fraction within 5% margin: 5.24%\n",
      "    Fraction within 10% margin: 10.98%\n",
      "    Fraction within 20% margin: 20.39%\n",
      "\n",
      "Dataset: IMDB-BINARY\n",
      "  Algorithm: HED\n",
      "    Fraction within 5% margin: 0.00%\n",
      "    Fraction within 10% margin: 0.00%\n",
      "    Fraction within 20% margin: 0.00%\n",
      "  Algorithm: IPFP\n",
      "    Fraction within 5% margin: 97.71%\n",
      "    Fraction within 10% margin: 97.85%\n",
      "    Fraction within 20% margin: 97.88%\n",
      "  Algorithm: SimGNN\n",
      "    Fraction within 5% margin: 0.68%\n",
      "    Fraction within 10% margin: 1.82%\n",
      "    Fraction within 20% margin: 3.64%\n",
      "\n",
      "Dataset: PROTEINS\n",
      "  Algorithm: HED\n",
      "    Fraction within 5% margin: 0.31%\n",
      "    Fraction within 10% margin: 0.40%\n",
      "    Fraction within 20% margin: 0.62%\n",
      "  Algorithm: IPFP\n",
      "    Fraction within 5% margin: 31.16%\n",
      "    Fraction within 10% margin: 60.37%\n",
      "    Fraction within 20% margin: 86.37%\n",
      "  Algorithm: SimGNN\n",
      "    Fraction within 5% margin: 0.05%\n",
      "    Fraction within 10% margin: 0.14%\n",
      "    Fraction within 20% margin: 0.34%\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T14:29:50.773198Z",
     "start_time": "2025-04-15T14:29:50.758977Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# List to accumulate memory usage stats for each dataset and algorithm.\n",
    "memory_stats = []\n",
    "\n",
    "# Iterate through each dataset and algorithm in the global 'data' dictionary.\n",
    "for dset, algos in data.items():\n",
    "    for algo, df in algos.items():\n",
    "        if 'memory_usage_mb' in df.columns:\n",
    "            mean_mem = df['memory_usage_mb'].mean()\n",
    "            max_mem = df['memory_usage_mb'].max()\n",
    "            std_mem = df['memory_usage_mb'].std()\n",
    "        else:\n",
    "            mean_mem = np.nan\n",
    "            max_mem = np.nan\n",
    "            std_mem = np.nan\n",
    "\n",
    "        memory_stats.append({\n",
    "            'Dataset': dset,\n",
    "            'Algorithm': algo,\n",
    "            'Mean Memory Usage (MB)': mean_mem,\n",
    "            'Max Memory Usage (MB)': max_mem,\n",
    "            'Std Memory Usage (MB)': std_mem\n",
    "        })\n",
    "\n",
    "# Create a DataFrame to display the results.\n",
    "memory_stats_df = pd.DataFrame(memory_stats)\n",
    "print(\"Memory Usage Statistics:\")\n",
    "print(memory_stats_df)"
   ],
   "id": "8f768ab570c3e76",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Usage Statistics:\n",
      "       Dataset Algorithm  Mean Memory Usage (MB)  Max Memory Usage (MB)  \\\n",
      "0         AIDS       HED                0.000157               0.257812   \n",
      "1         AIDS      IPFP             1566.556049            1580.175781   \n",
      "2         AIDS    SimGNN                0.000102               0.070312   \n",
      "3  IMDB-BINARY       HED                0.000008               0.257812   \n",
      "4  IMDB-BINARY      IPFP               41.433127              47.156250   \n",
      "5  IMDB-BINARY    SimGNN                0.023756               0.453125   \n",
      "6     PROTEINS       HED                0.000038               0.257812   \n",
      "7     PROTEINS      IPFP                0.000000               0.000000   \n",
      "8     PROTEINS    SimGNN                0.001087              10.718750   \n",
      "\n",
      "   Std Memory Usage (MB)  \n",
      "0               0.006369  \n",
      "1               6.157758  \n",
      "2               0.002157  \n",
      "3               0.001396  \n",
      "4               4.092402  \n",
      "5               0.050127  \n",
      "6               0.003128  \n",
      "7               0.000000  \n",
      "8               0.106243  \n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T14:29:50.880485Z",
     "start_time": "2025-04-15T14:29:50.866747Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def format_value(x):\n",
    "    if pd.isna(x):\n",
    "        return \"NaN\"\n",
    "    # For values less than 1 in magnitude, use scientific notation\n",
    "    if abs(x) < 1:\n",
    "        s = \"{:.1e}\".format(x)  # e.g., \"1.2e-01\"\n",
    "        mantissa, exp = s.split(\"e\")\n",
    "        exp = int(exp)\n",
    "        return f\"{mantissa} * 10^({exp})\"\n",
    "    # For values 1 or larger, show one decimal place normally.\n",
    "    return f\"{x:.2f}\"\n",
    "\n",
    "# List to accumulate memory usage stats for each dataset and algorithm.\n",
    "memory_stats = []\n",
    "\n",
    "# Iterate through each dataset and algorithm in the global `data` dictionary.\n",
    "for dset, algos in data.items():\n",
    "    for algo, df in algos.items():\n",
    "        if 'memory_usage_mb' in df.columns:\n",
    "            mean_mem = df['memory_usage_mb'].mean()\n",
    "            max_mem = df['memory_usage_mb'].max()\n",
    "            std_mem = df['memory_usage_mb'].std()\n",
    "        else:\n",
    "            mean_mem = np.nan\n",
    "            max_mem = np.nan\n",
    "            std_mem = np.nan\n",
    "\n",
    "        memory_stats.append({\n",
    "            'Dataset': dset,\n",
    "            'Algorithm': algo,\n",
    "            'Mean Memory Usage (MB)': format_value(mean_mem),\n",
    "            'Max Memory Usage (MB)': format_value(max_mem),\n",
    "            'Std Memory Usage (MB)': format_value(std_mem)\n",
    "        })\n",
    "\n",
    "# Create a DataFrame to display the results.\n",
    "memory_stats_df = pd.DataFrame(memory_stats)\n",
    "print(\"Memory Usage Statistics:\")\n",
    "print(memory_stats_df)"
   ],
   "id": "99c2c955cf73d2df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Usage Statistics:\n",
      "       Dataset Algorithm Mean Memory Usage (MB) Max Memory Usage (MB)  \\\n",
      "0         AIDS       HED          1.6 * 10^(-4)         2.6 * 10^(-1)   \n",
      "1         AIDS      IPFP                1566.56               1580.18   \n",
      "2         AIDS    SimGNN          1.0 * 10^(-4)         7.0 * 10^(-2)   \n",
      "3  IMDB-BINARY       HED          7.6 * 10^(-6)         2.6 * 10^(-1)   \n",
      "4  IMDB-BINARY      IPFP                  41.43                 47.16   \n",
      "5  IMDB-BINARY    SimGNN          2.4 * 10^(-2)         4.5 * 10^(-1)   \n",
      "6     PROTEINS       HED          3.8 * 10^(-5)         2.6 * 10^(-1)   \n",
      "7     PROTEINS      IPFP           0.0 * 10^(0)          0.0 * 10^(0)   \n",
      "8     PROTEINS    SimGNN          1.1 * 10^(-3)                 10.72   \n",
      "\n",
      "  Std Memory Usage (MB)  \n",
      "0         6.4 * 10^(-3)  \n",
      "1                  6.16  \n",
      "2         2.2 * 10^(-3)  \n",
      "3         1.4 * 10^(-3)  \n",
      "4                  4.09  \n",
      "5         5.0 * 10^(-2)  \n",
      "6         3.1 * 10^(-3)  \n",
      "7          0.0 * 10^(0)  \n",
      "8         1.1 * 10^(-1)  \n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T14:29:50.973525Z",
     "start_time": "2025-04-15T14:29:50.958326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# List to accumulate memory usage stats for each dataset and algorithm.\n",
    "memory_stats = []\n",
    "\n",
    "# Iterate through each dataset and algorithm in the global 'data' dictionary.\n",
    "for dset, algos in data.items():\n",
    "    for algo, df in algos.items():\n",
    "        if 'memory_usage_mb' in df.columns:\n",
    "            # Convert from MB to KB by multiplying by 1024.\n",
    "            mean_mem = df['memory_usage_mb'].mean() * 1024\n",
    "            max_mem = df['memory_usage_mb'].max() * 1024\n",
    "            std_mem = df['memory_usage_mb'].std() * 1024\n",
    "        else:\n",
    "            mean_mem = np.nan\n",
    "            max_mem = np.nan\n",
    "            std_mem = np.nan\n",
    "\n",
    "        memory_stats.append({\n",
    "            'Dataset': dset,\n",
    "            'Algorithm': algo,\n",
    "            'Mean Memory Usage (KB)': mean_mem,\n",
    "            'Max Memory Usage (KB)': max_mem,\n",
    "            'Std Memory Usage (KB)': std_mem\n",
    "        })\n",
    "\n",
    "# Create a DataFrame to display the results.\n",
    "memory_stats_df = pd.DataFrame(memory_stats)\n",
    "print(\"Memory Usage Statistics (in KB):\")\n",
    "print(memory_stats_df)"
   ],
   "id": "b6fb2295aa7a9c8b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Usage Statistics (in KB):\n",
      "       Dataset Algorithm  Mean Memory Usage (KB)  Max Memory Usage (KB)  \\\n",
      "0         AIDS       HED            1.611965e-01           2.639995e+02   \n",
      "1         AIDS      IPFP            1.604153e+06           1.618100e+06   \n",
      "2         AIDS    SimGNN            1.040513e-01           7.200000e+01   \n",
      "3  IMDB-BINARY       HED            7.745100e-03           2.639995e+02   \n",
      "4  IMDB-BINARY      IPFP            4.242752e+04           4.828800e+04   \n",
      "5  IMDB-BINARY    SimGNN            2.432612e+01           4.640000e+02   \n",
      "6     PROTEINS       HED            3.885774e-02           2.639995e+02   \n",
      "7     PROTEINS      IPFP            0.000000e+00           0.000000e+00   \n",
      "8     PROTEINS    SimGNN            1.113335e+00           1.097600e+04   \n",
      "\n",
      "   Std Memory Usage (KB)  \n",
      "0               6.521985  \n",
      "1            6305.544152  \n",
      "2               2.208633  \n",
      "3               1.429931  \n",
      "4            4190.620095  \n",
      "5              51.330161  \n",
      "6               3.202720  \n",
      "7               0.000000  \n",
      "8             108.792983  \n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T14:29:51.066436Z",
     "start_time": "2025-04-15T14:29:51.052977Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "44a190f79657c449",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
