{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Jupyter Notebook: ged_analysis.ipynb",
   "id": "ea6058fba4190c57"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Import necessary libraries",
   "id": "eac87d6baba1a520"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T12:18:38.274495Z",
     "start_time": "2025-03-13T12:18:36.584488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install --upgrade pip\n",
    "!{sys.executable} -m pip install ipywidgets\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Now import ipywidgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ],
   "id": "c5fbacaab67471d4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\r\n",
      "Requirement already satisfied: pip in /home/mfilippov/.local/lib/python3.8/site-packages (25.0.1)\r\n",
      "Defaulting to user installation because normal site-packages is not writeable\r\n",
      "Requirement already satisfied: ipywidgets in /home/mfilippov/.local/lib/python3.8/site-packages (8.1.5)\r\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/mfilippov/.local/lib/python3.8/site-packages (from ipywidgets) (0.2.2)\r\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/mfilippov/.local/lib/python3.8/site-packages (from ipywidgets) (8.12.3)\r\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/mfilippov/.local/lib/python3.8/site-packages (from ipywidgets) (5.14.3)\r\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /home/mfilippov/.local/lib/python3.8/site-packages (from ipywidgets) (4.0.13)\r\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /home/mfilippov/.local/lib/python3.8/site-packages (from ipywidgets) (3.0.13)\r\n",
      "Requirement already satisfied: backcall in /home/mfilippov/.local/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\r\n",
      "Requirement already satisfied: decorator in /home/mfilippov/.local/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\r\n",
      "Requirement already satisfied: jedi>=0.16 in /home/mfilippov/.local/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\r\n",
      "Requirement already satisfied: matplotlib-inline in /home/mfilippov/.local/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\r\n",
      "Requirement already satisfied: pickleshare in /home/mfilippov/.local/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\r\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /home/mfilippov/.local/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.50)\r\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/mfilippov/.local/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\r\n",
      "Requirement already satisfied: stack-data in /home/mfilippov/.local/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\r\n",
      "Requirement already satisfied: typing-extensions in /home/mfilippov/.local/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (4.12.2)\r\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/lib/python3/dist-packages (from ipython>=6.1.0->ipywidgets) (4.6.0)\r\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/mfilippov/.local/lib/python3.8/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\r\n",
      "Requirement already satisfied: wcwidth in /home/mfilippov/.local/lib/python3.8/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.13)\r\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/mfilippov/.local/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.0)\r\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/mfilippov/.local/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (3.0.0)\r\n",
      "Requirement already satisfied: pure-eval in /home/mfilippov/.local/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.3)\r\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Define utility functions (for loading, cleaning, computing metrics)",
   "id": "96def61da65e3995"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T12:18:38.327835Z",
     "start_time": "2025-03-13T12:18:38.315623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_approx_results(file_path):\n",
    "    \"\"\"\n",
    "    Load approximation results from an .xlsx file.\n",
    "    Expected columns:\n",
    "        'method', 'graph_id_1', 'graph_id_2', 'ged', 'accuracy', 'absolute_error', 'squared_error',\n",
    "        'runtime', 'memory_usage_mb', 'graph1_n', 'graph1_density', 'graph2_n', 'graph2_density',\n",
    "        'scalability'\n",
    "    Returns a cleaned DataFrame.\n",
    "    \"\"\"\n",
    "    df = pd.read_excel(file_path)\n",
    "\n",
    "    # Example of dropping empty rows or ignoring certain columns if not found\n",
    "    # You can adapt or refine these steps as needed:\n",
    "    df.dropna(how='all', inplace=True)  # drop rows that are entirely NaN\n",
    "    # You can also fill or ignore partial NaNs, e.g.:\n",
    "    # df['accuracy'] = df['accuracy'].fillna(0.0)  # or any strategy\n",
    "\n",
    "    # Convert columns to appropriate dtypes, if necessary\n",
    "    numeric_cols = ['ged', 'accuracy', 'absolute_error', 'squared_error',\n",
    "                    'runtime', 'memory_usage_mb', 'graph1_n', 'graph1_density',\n",
    "                    'graph2_n', 'graph2_density']\n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "    # Drop or ignore rows where critical values are missing\n",
    "    df.dropna(subset=['graph_id_1', 'graph_id_2', 'method'], inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def load_exact_results(file_path):\n",
    "    \"\"\"\n",
    "    Load exact GED results from an .xlsx file.\n",
    "    Relevant columns: 'graph_id_1', 'graph_id_2', 'min_ged', 'max_ged'\n",
    "    The exact GED is:\n",
    "       - median(min_ged, max_ged) if min_ged != max_ged\n",
    "       - min_ged (or max_ged) if they are equal\n",
    "    Returns a DataFrame with an additional 'ged_exact' column.\n",
    "    \"\"\"\n",
    "    df = pd.read_excel(file_path)\n",
    "    # Clean up, drop empty rows\n",
    "    df.dropna(how='all', inplace=True)\n",
    "\n",
    "    # Convert columns to numeric\n",
    "    for col in ['min_ged', 'max_ged']:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "    # Compute exact GED\n",
    "    df['ged_exact'] = df.apply(\n",
    "        lambda row: (row['min_ged'] + row['max_ged']) / 2\n",
    "                    if pd.notnull(row['min_ged'])\n",
    "                       and pd.notnull(row['max_ged'])\n",
    "                       and row['min_ged'] != row['max_ged']\n",
    "                    else row['min_ged'],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    df.dropna(subset=['graph_id_1', 'graph_id_2', 'ged_exact'], inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def compute_relative_accuracy(ged_approx, ged_exact):\n",
    "    \"\"\"\n",
    "    Relative accuracy measure (example).\n",
    "    If you have your own definition, replace accordingly.\n",
    "    \"\"\"\n",
    "    return 1.0 - abs(ged_approx - ged_exact) / ged_exact if ged_exact != 0 else np.nan\n",
    "\n",
    "def mean_absolute_error(approx_values, exact_values):\n",
    "    approx_values = np.array(approx_values)\n",
    "    exact_values = np.array(exact_values)\n",
    "    return np.mean(np.abs(approx_values - exact_values))\n",
    "\n",
    "def mean_squared_error(approx_values, exact_values):\n",
    "    approx_values = np.array(approx_values)\n",
    "    exact_values = np.array(exact_values)\n",
    "    return np.mean((approx_values - exact_values)**2)\n",
    "\n",
    "def compute_scalability(graph_sizes, runtimes, memory_usages):\n",
    "    \"\"\"\n",
    "    Compute scalability as the change in runtime and memory usage per unit increase in graph size.\n",
    "    Returns a tuple (slope_runtime, slope_memory).\n",
    "\n",
    "    Uses a simple linear regression (via numpy.polyfit).\n",
    "    \"\"\"\n",
    "    graph_sizes = np.array(graph_sizes, dtype=float)\n",
    "    runtimes = np.array(runtimes, dtype=float)\n",
    "    memory_usages = np.array(memory_usages, dtype=float)\n",
    "\n",
    "    slope_runtime, _ = np.polyfit(graph_sizes, runtimes, 1)\n",
    "    slope_memory, _ = np.polyfit(graph_sizes, memory_usages, 1)\n",
    "    return slope_runtime, slope_memory"
   ],
   "id": "ecc33b689b3b5f61",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Load and merge data",
   "id": "996c620874f13c95"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T12:21:01.037227Z",
     "start_time": "2025-03-13T12:18:38.364362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Modify these file paths to match your environment\n",
    "approx_file_hed   = \"/home/mfilippov/ged_data/results/gedlib/PROTEINS/PROTEINS_HED_results.xlsx\"\n",
    "approx_file_ipfp  = \"/home/mfilippov/ged_data/results/gedlib/PROTEINS/PROTEINS_IPFP_results.xlsx\"\n",
    "approx_file_simgnn= \"/home/mfilippov/ged_data/results/neural/PROTEINS/performance_130325.xlsx\"\n",
    "exact_file        = \"/home/mfilippov/ged_data/results/exact_ged/PROTEINS/merged/results.xlsx\"\n",
    "\n",
    "df_hed    = load_approx_results(approx_file_hed)\n",
    "df_ipfp   = load_approx_results(approx_file_ipfp)\n",
    "df_simgnn = load_approx_results(approx_file_simgnn)\n",
    "\n",
    "df_exact  = load_exact_results(exact_file)\n",
    "\n",
    "# Merge each approximate DataFrame with the exact GED DataFrame\n",
    "# We'll keep track of which method each row belongs to so we can unify the data for plotting.\n",
    "df_hed_merged = pd.merge(df_hed, df_exact, on=['graph_id_1','graph_id_2'], how='left')\n",
    "df_ipfp_merged = pd.merge(df_ipfp, df_exact, on=['graph_id_1','graph_id_2'], how='left')\n",
    "df_simgnn_merged = pd.merge(df_simgnn, df_exact, on=['graph_id_1','graph_id_2'], how='left')\n",
    "\n",
    "# Combine all in one DataFrame for convenience if needed\n",
    "df_all = pd.concat([df_hed_merged, df_ipfp_merged, df_simgnn_merged], ignore_index=True)\n",
    "\n",
    "# Clean out any rows with missing critical fields\n",
    "df_all.dropna(subset=['ged_exact','ged','method'], inplace=True)"
   ],
   "id": "b075d7e5c1defed8",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Example: Compute or update metrics as needed",
   "id": "882d3a8e8fa8d155"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T12:21:01.180109Z",
     "start_time": "2025-03-13T12:21:01.104156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# If the columns 'accuracy', 'absolute_error', or 'squared_error' in the loaded data\n",
    "# are not what you want, or you want to re-compute them, you can do that here:\n",
    "df_all['absolute_error'] = abs(df_all['ged'] - df_all['ged_exact'])\n",
    "df_all['squared_error']  = (df_all['ged'] - df_all['ged_exact'])**2\n",
    "df_all['accuracy']       = df_all.apply(\n",
    "    lambda row: compute_relative_accuracy(row['ged'], row['ged_exact']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# We might also unify a \"graph_size\" for easy filtering/plotting\n",
    "# e.g. we consider the average size of the two graphs in a pair:\n",
    "df_all['graph_size'] = (df_all['graph1_n'] + df_all['graph2_n']) / 2.0\n",
    "\n",
    "# Similarly for \"graph_density\":\n",
    "df_all['graph_density'] = (df_all['graph1_density'] + df_all['graph2_density']) / 2.0\n"
   ],
   "id": "5489bbd3c7560378",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. Interactive Plotting",
   "id": "9e7c90ff8359089c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T12:21:01.191992Z",
     "start_time": "2025-03-13T12:21:01.183738Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_accuracy_vs_size(df, node_range=(0,150)):\n",
    "    \"\"\"\n",
    "    Plots accuracy vs. average graph size.\n",
    "    Allows filtering by a node range (e.g. <50, 50-100, >100).\n",
    "    \"\"\"\n",
    "    # Filter data\n",
    "    df_filtered = df[(df['graph_size'] >= node_range[0]) & (df['graph_size'] <= node_range[1])]\n",
    "\n",
    "    # Create high-resolution plot\n",
    "    plt.figure(figsize=(10, 6), dpi=120)\n",
    "\n",
    "    # We'll plot each method separately\n",
    "    methods = df_filtered['method'].unique()\n",
    "    for m in methods:\n",
    "        sub = df_filtered[df_filtered['method'] == m]\n",
    "        plt.scatter(sub['graph_size'], sub['accuracy'], label=m, alpha=0.7)\n",
    "\n",
    "    plt.title(f\"Accuracy vs. Graph Size\\nNode range: {node_range}\")\n",
    "    plt.xlabel(\"Average Graph Size (# nodes)\")\n",
    "    plt.ylabel(\"Relative Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_runtime_vs_size(df, node_range=(0,150)):\n",
    "    \"\"\"\n",
    "    Plots runtime vs. average graph size.\n",
    "    \"\"\"\n",
    "    df_filtered = df[(df['graph_size'] >= node_range[0]) & (df['graph_size'] <= node_range[1])]\n",
    "\n",
    "    plt.figure(figsize=(10, 6), dpi=120)\n",
    "\n",
    "    methods = df_filtered['method'].unique()\n",
    "    for m in methods:\n",
    "        sub = df_filtered[df_filtered['method'] == m]\n",
    "        plt.scatter(sub['graph_size'], sub['runtime'], label=m, alpha=0.7)\n",
    "\n",
    "    plt.title(f\"Runtime vs. Graph Size\\nNode range: {node_range}\")\n",
    "    plt.xlabel(\"Average Graph Size (# nodes)\")\n",
    "    plt.ylabel(\"Runtime (s)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_accuracy_vs_density(df, density_range=(0,1.0)):\n",
    "    \"\"\"\n",
    "    Plots accuracy vs. average graph density.\n",
    "    \"\"\"\n",
    "    df_filtered = df[(df['graph_density'] >= density_range[0]) & (df['graph_density'] <= density_range[1])]\n",
    "\n",
    "    plt.figure(figsize=(10, 6), dpi=120)\n",
    "\n",
    "    methods = df_filtered['method'].unique()\n",
    "    for m in methods:\n",
    "        sub = df_filtered[df_filtered['method'] == m]\n",
    "        plt.scatter(sub['graph_density'], sub['accuracy'], label=m, alpha=0.7)\n",
    "\n",
    "    plt.title(f\"Accuracy vs. Graph Density\\nDensity range: {density_range}\")\n",
    "    plt.xlabel(\"Average Graph Density\")\n",
    "    plt.ylabel(\"Relative Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_error_vs_runtime(df):\n",
    "    \"\"\"\n",
    "    Trade-off plot: average error (distance from exact GED) vs. average runtime, by method.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6), dpi=120)\n",
    "\n",
    "    methods = df['method'].unique()\n",
    "    # We'll compute average error, average runtime by method\n",
    "    for m in methods:\n",
    "        sub = df[df['method'] == m]\n",
    "        avg_error = sub['absolute_error'].mean()\n",
    "        avg_runtime = sub['runtime'].mean()\n",
    "        plt.scatter(avg_runtime, avg_error, label=m, s=100)  # bigger marker\n",
    "\n",
    "    plt.title(\"Trade-off: Average Error vs. Average Runtime\")\n",
    "    plt.xlabel(\"Average Runtime (s)\")\n",
    "    plt.ylabel(\"Average Absolute Error\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ],
   "id": "a745732ccdd2ad3e",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6. Add interactive controls (ipywidgets)",
   "id": "ee7fa3a977e0d797"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T12:21:02.365806Z",
     "start_time": "2025-03-13T12:21:01.235944Z"
    }
   },
   "cell_type": "code",
   "source": [
    "node_slider = widgets.IntRangeSlider(\n",
    "    value=[0, 150],\n",
    "    min=0,\n",
    "    max=300,\n",
    "    step=1,\n",
    "    description='Node range:',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "density_slider = widgets.FloatRangeSlider(\n",
    "    value=[0.0, 1.0],\n",
    "    min=0.0,\n",
    "    max=2.0,  # set upper bound as needed\n",
    "    step=0.01,\n",
    "    description='Density range:',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "# We'll define interactive wrappers so the user can adjust node/density range:\n",
    "@interact(node_range=node_slider)\n",
    "def interactive_accuracy_vs_size(node_range):\n",
    "    return plot_accuracy_vs_size(df_all, node_range=node_range)\n",
    "\n",
    "@interact(node_range=node_slider)\n",
    "def interactive_runtime_vs_size(node_range):\n",
    "    return plot_runtime_vs_size(df_all, node_range=node_range)\n",
    "\n",
    "@interact(density_range=density_slider)\n",
    "def interactive_accuracy_vs_density(density_range):\n",
    "    return plot_accuracy_vs_density(df_all, density_range=density_range)\n",
    "\n",
    "\n",
    "# The trade-off plot might not require a range slider:\n",
    "plot_error_vs_runtime(df_all)"
   ],
   "id": "c14b8e63e698fb58",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "interactive(children=(IntRangeSlider(value=(0, 150), continuous_update=False, description='Node range:', max=3…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fa8fbade3c664bbf9d01a14d038e9aa5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "interactive(children=(IntRangeSlider(value=(0, 150), continuous_update=False, description='Node range:', max=3…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "da5a43af2db34512a2424d5596b7978d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "interactive(children=(FloatRangeSlider(value=(0.0, 1.0), continuous_update=False, description='Density range:'…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2ba86286e90c461786e8e8930a0e944a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'runtime'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py:3653\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3652\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3653\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3654\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/index.pyx:147\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/index.pyx:176\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'runtime'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 34\u001B[0m\n\u001B[1;32m     30\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m plot_accuracy_vs_density(df_all, density_range\u001B[38;5;241m=\u001B[39mdensity_range)\n\u001B[1;32m     33\u001B[0m \u001B[38;5;66;03m# The trade-off plot might not require a range slider:\u001B[39;00m\n\u001B[0;32m---> 34\u001B[0m \u001B[43mplot_error_vs_runtime\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf_all\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[9], line 79\u001B[0m, in \u001B[0;36mplot_error_vs_runtime\u001B[0;34m(df)\u001B[0m\n\u001B[1;32m     77\u001B[0m     sub \u001B[38;5;241m=\u001B[39m df[df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmethod\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m==\u001B[39m m]\n\u001B[1;32m     78\u001B[0m     avg_error \u001B[38;5;241m=\u001B[39m sub[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mabsolute_error\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mmean()\n\u001B[0;32m---> 79\u001B[0m     avg_runtime \u001B[38;5;241m=\u001B[39m \u001B[43msub\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mruntime\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mmean()\n\u001B[1;32m     80\u001B[0m     plt\u001B[38;5;241m.\u001B[39mscatter(avg_runtime, avg_error, label\u001B[38;5;241m=\u001B[39mm, s\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m)  \u001B[38;5;66;03m# bigger marker\u001B[39;00m\n\u001B[1;32m     82\u001B[0m plt\u001B[38;5;241m.\u001B[39mtitle(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTrade-off: Average Error vs. Average Runtime\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py:3761\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   3760\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 3761\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3762\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   3763\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py:3655\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3653\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[1;32m   3654\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m-> 3655\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3656\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3657\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3658\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3659\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[1;32m   3660\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'runtime'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
