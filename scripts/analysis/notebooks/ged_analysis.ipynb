{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Jupyter Notebook: ged_analysis.ipynb",
   "id": "ea6058fba4190c57"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Import necessary libraries",
   "id": "eac87d6baba1a520"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T10:37:08.466482Z",
     "start_time": "2025-03-14T10:37:05.053765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install --upgrade pip\n",
    "!{sys.executable} -m pip install ipywidgets\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Now import ipywidgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ],
   "id": "c5fbacaab67471d4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: pip in c:\\users\\mikef\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (25.0.1)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\mikef\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (8.1.5)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\mikef\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\mikef\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipywidgets) (8.18.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\mikef\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in c:\\users\\mikef\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in c:\\users\\mikef\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: decorator in c:\\users\\mikef\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\mikef\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\mikef\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\mikef\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\mikef\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\mikef\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\mikef\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (4.12.2)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\mikef\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (1.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\mikef\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\mikef\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\mikef\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\mikef\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\mikef\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\mikef\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.3)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Define utility functions (for loading, cleaning, computing metrics)",
   "id": "96def61da65e3995"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T10:37:08.543553Z",
     "start_time": "2025-03-14T10:37:08.485484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_approx_results(file_path, fill_n_density=None):\n",
    "    \"\"\"\n",
    "    Load approximation results from an XLSX file.\n",
    "\n",
    "    If `fill_n_density` is provided, it should be a DataFrame (e.g., the SimGNN data)\n",
    "    that has 'graph_id_1', 'graph_id_2', 'graph1_n', 'graph2_n', 'graph1_density', 'graph2_density'.\n",
    "    We'll merge those columns into the loaded DataFrame as needed.\n",
    "    \"\"\"\n",
    "    df = pd.read_excel(file_path)\n",
    "\n",
    "    # Clean up\n",
    "    df.dropna(how='all', inplace=True)  # drop empty rows\n",
    "\n",
    "    # Convert to numeric where applicable\n",
    "    numeric_cols = [\n",
    "        'ged', 'accuracy', 'absolute_error', 'squared_error',\n",
    "        'runtime', 'memory_usage_mb',\n",
    "        'graph1_n', 'graph1_density', 'graph2_n', 'graph2_density'\n",
    "    ]\n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "    # If we have a reference DF with node-count & density, fill them in where missing\n",
    "    if fill_n_density is not None:\n",
    "        # We'll merge on graph_id_1, graph_id_2\n",
    "        # but keep existing columns if they already have data\n",
    "        needed_cols = ['graph1_n', 'graph2_n', 'graph1_density', 'graph2_density']\n",
    "\n",
    "        # Create a slim reference with just the ID pairs + those columns\n",
    "        ref_cols = ['graph_id_1', 'graph_id_2'] + needed_cols\n",
    "        ref = fill_n_density[ref_cols].copy().drop_duplicates()\n",
    "\n",
    "        # Merge using left join so that approximate results remain in place\n",
    "        merged = pd.merge(\n",
    "            df, ref,\n",
    "            how='left',\n",
    "            on=['graph_id_1', 'graph_id_2'],\n",
    "            suffixes=('', '_ref')\n",
    "        )\n",
    "\n",
    "        # Fill missing from _ref\n",
    "        for c in needed_cols:\n",
    "            merged[c] = np.where(\n",
    "                merged[c].isna(),\n",
    "                merged[f\"{c}_ref\"],\n",
    "                merged[c]\n",
    "            )\n",
    "        # Clean leftover columns\n",
    "        drop_cols = [f\"{c}_ref\" for c in needed_cols if f\"{c}_ref\" in merged.columns]\n",
    "        merged.drop(columns=drop_cols, inplace=True)\n",
    "\n",
    "        df = merged\n",
    "\n",
    "    # Some final cleanup if needed\n",
    "    df.dropna(subset=['graph_id_1', 'graph_id_2'], inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_exact_results(file_path):\n",
    "    \"\"\"\n",
    "    Load exact GED results from an XLSX file.\n",
    "    Compute 'ged_exact' as the median of (min_ged, max_ged) if they differ,\n",
    "    else min_ged (or max_ged).\n",
    "    \"\"\"\n",
    "    df = pd.read_excel(file_path)\n",
    "    df.dropna(how='all', inplace=True)\n",
    "\n",
    "    for col in ['min_ged', 'max_ged']:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "    def compute_ged_exact(row):\n",
    "        if pd.notnull(row['min_ged']) and pd.notnull(row['max_ged']) and row['min_ged'] != row['max_ged']:\n",
    "            return (row['min_ged'] + row['max_ged']) / 2.0\n",
    "        else:\n",
    "            return row['min_ged']  # or row['max_ged']\n",
    "\n",
    "    df['ged_exact'] = df.apply(compute_ged_exact, axis=1)\n",
    "    df.dropna(subset=['graph_id_1', 'graph_id_2', 'ged_exact'], inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def compute_relative_accuracy(ged_approx, ged_exact):\n",
    "    \"\"\"\n",
    "    Relative accuracy measure (example).\n",
    "    If you have your own definition, replace accordingly.\n",
    "    \"\"\"\n",
    "    return 1.0 - abs(ged_approx - ged_exact) / ged_exact if ged_exact != 0 else np.nan\n",
    "\n",
    "def mean_absolute_error(approx_values, exact_values):\n",
    "    approx_values = np.array(approx_values)\n",
    "    exact_values = np.array(exact_values)\n",
    "    return np.mean(np.abs(approx_values - exact_values))\n",
    "\n",
    "def mean_squared_error(approx_values, exact_values):\n",
    "    approx_values = np.array(approx_values)\n",
    "    exact_values = np.array(exact_values)\n",
    "    return np.mean((approx_values - exact_values)**2)\n",
    "\n",
    "def compute_scalability(graph_sizes, runtimes, memory_usages):\n",
    "    \"\"\"\n",
    "    Compute scalability as the change in runtime and memory usage per unit increase in graph size.\n",
    "    Returns a tuple (slope_runtime, slope_memory).\n",
    "\n",
    "    Uses a simple linear regression (via numpy.polyfit).\n",
    "    \"\"\"\n",
    "    graph_sizes = np.array(graph_sizes, dtype=float)\n",
    "    runtimes = np.array(runtimes, dtype=float)\n",
    "    memory_usages = np.array(memory_usages, dtype=float)\n",
    "\n",
    "    slope_runtime, _ = np.polyfit(graph_sizes, runtimes, 1)\n",
    "    slope_memory, _ = np.polyfit(graph_sizes, memory_usages, 1)\n",
    "    return slope_runtime, slope_memory"
   ],
   "id": "ecc33b689b3b5f61",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Define file paths for each dataset & method",
   "id": "996c620874f13c95"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T10:42:47.056347Z",
     "start_time": "2025-03-14T10:42:47.042344Z"
    }
   },
   "cell_type": "code",
   "source": [
    "datasets = {\n",
    "    \"PROTEINS\": {\n",
    "        \"HED\":      r\"C:\\project_data\\results\\gedlib\\PROTEINS\\PROTEINS_HED_results.xlsx\",\n",
    "        \"IPFP\":     r\"C:\\project_data\\results\\gedlib\\PROTEINS\\PROTEINS_IPFP_results.xlsx\",\n",
    "        \"SimGNN\":   r\"C:\\project_data\\results\\simgnn\\PROTEINS\\performance.xlsx\",\n",
    "        \"Exact\":    r\"C:\\project_data\\results\\exact_ged\\PROTEINS\\merged\\results.xlsx\"\n",
    "    },\n",
    "    \"AIDS\": {\n",
    "        \"HED\":      r\"C:\\project_data\\results\\gedlib\\AIDS\\AIDS_HED_results.xlsx\",\n",
    "        \"IPFP\":     r\"C:\\project_data\\results\\gedlib\\AIDS\\AIDS_IPFP_results.xlsx\",\n",
    "        \"SimGNN\":   r\"C:\\project_data\\results\\simgnn\\AIDS\\performance.xlsx\",\n",
    "        \"Exact\":    r\"C:\\project_data\\results\\exact_ged\\AIDS\\merged\\results.xlsx\"\n",
    "    },\n",
    "    \"IMDB-BINARY\": {\n",
    "        \"HED\":      r\"C:\\project_data\\results\\gedlib\\IMDB-BINARY\\IMDB-BINARY_HED_results.xlsx\",\n",
    "        \"IPFP\":     r\"C:\\project_data\\results\\gedlib\\IMDB-BINARY\\IMDB-BINARY_IPFP_results.xlsx\",\n",
    "        \"SimGNN\":   r\"C:\\project_data\\results\\simgnn\\IMDB-BINARY\\performance.xlsx\",\n",
    "        \"Exact\":    r\"C:\\project_data\\results\\exact_ged\\IMDB-BINARY\\merged\\results.xlsx\"\n",
    "    }\n",
    "}"
   ],
   "id": "b075d7e5c1defed8",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Load data for each dataset & method",
   "id": "882d3a8e8fa8d155"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T10:47:25.525527Z",
     "start_time": "2025-03-14T10:42:52.088842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = {}\n",
    "\n",
    "for dset, paths in datasets.items():\n",
    "    # Load the SimGNN (since we might want to fill missing columns from it)\n",
    "    df_simgnn = load_approx_results(paths[\"SimGNN\"])\n",
    "\n",
    "    # Load exact GED\n",
    "    df_exact = load_exact_results(paths[\"Exact\"])\n",
    "\n",
    "    # Load HED, IPFP, SimGNN (again, but now with fill from the same df_simgnn if needed)\n",
    "    df_hed   = load_approx_results(paths[\"HED\"], fill_n_density=df_simgnn)\n",
    "    df_ipfp  = load_approx_results(paths[\"IPFP\"], fill_n_density=df_simgnn)\n",
    "    # For consistency, we can also re-load or re-use df_simgnn with fill from itself\n",
    "    # but typically it already has the columns, so no special fill needed\n",
    "    # We'll do it just for demonstration:\n",
    "    df_simgnn_filled = load_approx_results(paths[\"SimGNN\"], fill_n_density=df_simgnn)\n",
    "\n",
    "    # Merge each approximate with exact for in-memory computations\n",
    "    # (We do not physically merge to a single big file, just a left join so we have ged_exact.)\n",
    "    df_hed   = pd.merge(df_hed,   df_exact, on=['graph_id_1','graph_id_2'], how='left', suffixes=('', '_exact'))\n",
    "    df_ipfp  = pd.merge(df_ipfp,  df_exact, on=['graph_id_1','graph_id_2'], how='left', suffixes=('', '_exact'))\n",
    "    df_simgnn_filled = pd.merge(df_simgnn_filled, df_exact, on=['graph_id_1','graph_id_2'], how='left', suffixes=('', '_exact'))\n",
    "\n",
    "    # Compute or recast metrics if columns are missing\n",
    "    for df_approx in [df_hed, df_ipfp, df_simgnn_filled]:\n",
    "        if 'ged_exact' in df_approx.columns and 'ged' in df_approx.columns:\n",
    "            # absolute_error, etc.\n",
    "            df_approx['absolute_error'] = abs(df_approx['ged'] - df_approx['ged_exact'])\n",
    "            df_approx['squared_error']  = (df_approx['ged'] - df_approx['ged_exact'])**2\n",
    "            df_approx['accuracy']       = df_approx.apply(\n",
    "                lambda row: compute_relative_accuracy(row['ged'], row['ged_exact'])\n",
    "                            if pd.notnull(row['ged_exact']) else np.nan,\n",
    "                axis=1\n",
    "            )\n",
    "            # Might also define average graph size, density:\n",
    "            df_approx['graph_size'] = (df_approx['graph1_n'] + df_approx['graph2_n']) / 2.0\n",
    "            df_approx['graph_density'] = (df_approx['graph1_density'] + df_approx['graph2_density']) / 2.0\n",
    "\n",
    "    # Store final data for this dataset\n",
    "    data[dset] = {\n",
    "        \"HED\": df_hed,\n",
    "        \"IPFP\": df_ipfp,\n",
    "        \"SimGNN\": df_simgnn_filled\n",
    "    }\n"
   ],
   "id": "5489bbd3c7560378",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "['graph_id_1', 'graph_id_2']",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_2280\\1585477639.py\u001B[0m in \u001B[0;36m?\u001B[1;34m()\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m{\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m \u001B[1;32mfor\u001B[0m \u001B[0mdset\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpaths\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mdatasets\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m     \u001B[1;31m# Load the SimGNN (since we might want to fill missing columns from it)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m     \u001B[0mdf_simgnn\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mload_approx_results\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpaths\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"SimGNN\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_2280\\2835059186.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(file_path, fill_n_density)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     53\u001B[0m         \u001B[0mdf\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmerged\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     54\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     55\u001B[0m     \u001B[1;31m# Some final cleanup if needed\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 56\u001B[1;33m     \u001B[0mdf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdropna\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msubset\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'graph_id_1'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'graph_id_2'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minplace\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     57\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     58\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mdf\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, axis, how, thresh, subset, inplace, ignore_index)\u001B[0m\n\u001B[0;32m   6666\u001B[0m             \u001B[0max\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get_axis\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0magg_axis\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   6667\u001B[0m             \u001B[0mindices\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0max\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_indexer_for\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msubset\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   6668\u001B[0m             \u001B[0mcheck\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mindices\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   6669\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mcheck\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0many\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 6670\u001B[1;33m                 \u001B[1;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msubset\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mcheck\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtolist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   6671\u001B[0m             \u001B[0magg_obj\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtake\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindices\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0magg_axis\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   6672\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   6673\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mthresh\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mlib\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mno_default\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: ['graph_id_1', 'graph_id_2']"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. Generate correlation plots for each dataset",
   "id": "9e7c90ff8359089c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T10:37:09.146777900Z",
     "start_time": "2025-03-13T12:21:01.183738Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# (A) 3 plots to show correlation between accuracy & graph size (small, medium, large).\n",
    "# We'll define a function that loops over the chosen dataset and method\n",
    "# and makes scatter plots or box plots.\n",
    "\n",
    "def plot_accuracy_vs_size_ranges(dset, method):\n",
    "    \"\"\"\n",
    "    For a given dataset (e.g. 'PROTEINS') and method (e.g. 'HED'),\n",
    "    produce 3 separate plots for:\n",
    "      1) small (<50 nodes)\n",
    "      2) medium (50-100)\n",
    "      3) large (>100)\n",
    "    We'll show scatter plots of (graph_size vs accuracy).\n",
    "    \"\"\"\n",
    "    df = data[dset][method]\n",
    "    df_valid = df.dropna(subset=['graph_size','accuracy'])\n",
    "\n",
    "    # Define the 3 size bins:\n",
    "    small_df  = df_valid[df_valid['graph_size'] < 50]\n",
    "    medium_df = df_valid[(df_valid['graph_size'] >= 50) & (df_valid['graph_size'] <= 100)]\n",
    "    large_df  = df_valid[df_valid['graph_size'] > 100]\n",
    "\n",
    "    # 1) Plot small\n",
    "    plt.figure(figsize=(6,4), dpi=120)\n",
    "    plt.scatter(small_df['graph_size'], small_df['accuracy'], alpha=0.6)\n",
    "    plt.title(f\"{dset} - {method} (Small <50 nodes)\")\n",
    "    plt.xlabel(\"Average Graph Size\")\n",
    "    plt.ylabel(\"Relative Accuracy\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # 2) Plot medium\n",
    "    plt.figure(figsize=(6,4), dpi=120)\n",
    "    plt.scatter(medium_df['graph_size'], medium_df['accuracy'], alpha=0.6)\n",
    "    plt.title(f\"{dset} - {method} (Medium 50-100 nodes)\")\n",
    "    plt.xlabel(\"Average Graph Size\")\n",
    "    plt.ylabel(\"Relative Accuracy\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # 3) Plot large\n",
    "    plt.figure(figsize=(6,4), dpi=120)\n",
    "    plt.scatter(large_df['graph_size'], large_df['accuracy'], alpha=0.6)\n",
    "    plt.title(f\"{dset} - {method} (Large >100 nodes)\")\n",
    "    plt.xlabel(\"Average Graph Size\")\n",
    "    plt.ylabel(\"Relative Accuracy\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# (B) 2 plots for graphs of varying densities (sparse vs. dense).\n",
    "# We'll define a function that picks a threshold or uses some percentile to define \"sparse\" vs. \"dense\".\n",
    "\n",
    "def plot_accuracy_vs_density(dset, method, density_threshold=0.1):\n",
    "    \"\"\"\n",
    "    Creates two plots: one for \"sparse\" (density < threshold),\n",
    "    and one for \"dense\" (density >= threshold).\n",
    "    \"\"\"\n",
    "    df = data[dset][method]\n",
    "    df_valid = df.dropna(subset=['graph_density','accuracy'])\n",
    "\n",
    "    sparse_df = df_valid[df_valid['graph_density'] < density_threshold]\n",
    "    dense_df  = df_valid[df_valid['graph_density'] >= density_threshold]\n",
    "\n",
    "    # Sparse\n",
    "    plt.figure(figsize=(6,4), dpi=120)\n",
    "    plt.scatter(sparse_df['graph_density'], sparse_df['accuracy'], alpha=0.6)\n",
    "    plt.title(f\"{dset} - {method} (Sparse < {density_threshold})\")\n",
    "    plt.xlabel(\"Average Graph Density\")\n",
    "    plt.ylabel(\"Relative Accuracy\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Dense\n",
    "    plt.figure(figsize=(6,4), dpi=120)\n",
    "    plt.scatter(dense_df['graph_density'], dense_df['accuracy'], alpha=0.6)\n",
    "    plt.title(f\"{dset} - {method} (Dense >= {density_threshold})\")\n",
    "    plt.xlabel(\"Average Graph Density\")\n",
    "    plt.ylabel(\"Relative Accuracy\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ],
   "id": "a745732ccdd2ad3e",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6. Usage",
   "id": "894f3b626fcc0f83"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    " #Example: produce the 3 size correlation plots + 2 density plots for PROTEINS/HED\n",
    "plot_accuracy_vs_size_ranges(dset=\"PROTEINS\", method=\"HED\")\n",
    "plot_accuracy_vs_density(dset=\"PROTEINS\", method=\"HED\", density_threshold=0.1)\n",
    "\n",
    "# You can repeat for each method or dataset as needed:\n",
    "# plot_accuracy_vs_size_ranges(\"PROTEINS\", \"IPFP\")\n",
    "# plot_accuracy_vs_density(\"PROTEINS\", \"IPFP\", density_threshold=0.1)"
   ],
   "id": "2c6cae0dadfebdf7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
